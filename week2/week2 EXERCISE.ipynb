{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbe91b-1590-4a03-be64-91b9caaf582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f9bb06a5-2cac-40f5-a1fa-ccd44d4fd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "22655286-29d1-47d5-afc6-f58efa2803f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and beings sk-proj-\n"
     ]
    }
   ],
   "source": [
    "#Initialization\n",
    "\n",
    "#load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "#get Open AI API Key from loaded environment\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and beings {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key does not exists\")\n",
    "\n",
    "#initialize openai\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "response = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5850ae42-fdf8-4a2a-bdf6-5bc14f5301bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a historian specializing in marathi literature and history. When asked about past, give the answer and supplement with poetic descriptions.\n",
    "\n",
    "When image generation properties are required, you MUST ALWAYS use the 'get_properties_for_image' tool. You MUST always use tool only once per user request\n",
    "\n",
    "Example of tool use:\n",
    "User: Tell me about Chhatrapti Shivaji Maharaj.\n",
    "Tool: get_properties_for_image\n",
    "Tool Arguments:\n",
    "{\n",
    "\"object_name\": \"Chhatrapati Shivaji Maharaj\",\n",
    "\"object_description\": \"A 17th-century Indian warrior king and a member of the Bhonsle Maratha clan.\",\n",
    "\"object_poetic_description\": \"The lion of the Sahyadri, his valor a legend, his wisdom a guiding light.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b17d2321-452f-4a8c-b32e-60990fe64b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_properties_for_image = {\n",
    "    \"name\": \"get_properties_for_image\",\n",
    "    \"description\": \"Extract the object name, description, and poetic description required to generate an image. This tool should be used when the user requests an image or when the context implies an image would be useful.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"object_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the object for which information is requested for\",\n",
    "            },\n",
    "            \"object_description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The description of the object\",\n",
    "            },\n",
    "            \"object_poetic_description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The poetic description of the object\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"object_name\",\"object_description\",\"object_poetic_description\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": get_properties_for_image}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "82a8c4eb-d61e-4cc4-b97e-ec697efc7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(obj, description):\n",
    "    image_response = openai.images.generate(\n",
    "        model = \"dall-e-3\",\n",
    "        prompt=f\"An image representing the {obj} based on the provided {description}\",\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "        response_format=\"b64_json\",\n",
    "    )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "631d5f0c-f67b-4d16-9829-8d562221c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\":\"system\",\"content\":system_message}]+history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    image=None\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        messages.append(message)\n",
    "        tool_calls = message.tool_calls\n",
    "        for tool_call in tool_calls:\n",
    "            print(tool_call.function.name)\n",
    "            print(tool_call.id)\n",
    "            if tool_call.function.name == \"get_properties_for_image\":\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "                obj_name = arguments.get(\"object_name\")\n",
    "                obj_description = arguments.get(\"object_description\")\n",
    "                obj_poetic_description = arguments.get(\"object_poetic_description\")\n",
    "                \n",
    "                image = artist(obj_name, obj_poetic_description)\n",
    "                # Add tool response to messages\n",
    "                tool_response = {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": json.dumps({\"image_generation\" : \"success\"}), #only include the result of the tool.\n",
    "                }\n",
    "                messages.append(tool_response)\n",
    "\n",
    "        print(messages)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "\n",
    "    if response.choices[0].message.content:\n",
    "        reply = response.choices[0].message.content\n",
    "    else:\n",
    "        reply = \"Image Generated\"\n",
    "\n",
    "    history += [{\"role\":\"assistant\",\"content\":reply}]\n",
    "\n",
    "    return history, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ef851d80-d69e-4b3b-b252-32b30cb3aa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7906\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7906/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500,type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history = [{\"role\":\"user\",\"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry,chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab44c7a-46cc-4c65-8a7e-7fd5ea72b08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76d240-4781-49fc-b034-4b3274c4734e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
